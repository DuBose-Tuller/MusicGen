{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get aligned MusicGen predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/DAVIDSON/dutuller/Workspace/DRI1/MusicGen/\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import yaml\n",
    "from embeddings.h5_processor import H5DataProcessor, DatasetConfig, ProcessedDataset\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infrastructure for loading and splitting the embedding data from storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"universal_music/NHS_full.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Process datasets using H5DataProcessor\n",
    "processor = H5DataProcessor()\n",
    "all_train_data = []\n",
    "all_test_data = []\n",
    "class_names = set()\n",
    "\n",
    "# Process each dataset and split\n",
    "for dataset_config in config['datasets']:\n",
    "    dataset = processor.process_h5_file(\n",
    "        processor.get_embedding_path(DatasetConfig(**dataset_config)),\n",
    "        DatasetConfig(**dataset_config)\n",
    "    )\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_data, test_data = processor.get_train_test_split(\n",
    "        dataset, \n",
    "        test_ratio=0.2,\n",
    "        random_seed=42\n",
    "    )\n",
    "    \n",
    "    all_train_data.append(train_data)\n",
    "    all_test_data.append(test_data)\n",
    "    class_names.update(dataset.labels)\n",
    "\n",
    "# Combine datasets\n",
    "train_data = ProcessedDataset(\n",
    "    embeddings=np.vstack([d.embeddings for d in all_train_data]),\n",
    "    labels=[l for d in all_train_data for l in d.labels],\n",
    "    filenames=[f for d in all_train_data for f in d.filenames],\n",
    "    name=\"combined\",\n",
    "    num_samples=sum(d.num_samples for d in all_train_data)\n",
    ")\n",
    "\n",
    "test_data = ProcessedDataset(\n",
    "    embeddings=np.vstack([d.embeddings for d in all_test_data]),\n",
    "    labels=[l for d in all_test_data for l in d.labels],\n",
    "    filenames=[f for d in all_test_data for f in d.filenames],\n",
    "    name=\"combined\",\n",
    "    num_samples=sum(d.num_samples for d in all_test_data)\n",
    ")\n",
    "\n",
    "# Create and configure model\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier on the full songs from the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mapping for string class labels\n",
    "unique_labels = sorted(set(train_data.labels + test_data.labels))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert labels to indices\n",
    "X_train = train_data.embeddings\n",
    "y_train = np.array([label_to_idx[label] for label in train_data.labels])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify which song ids are present in the test set, so that we can find them among the sample audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_song_ids = [int(re.search(r\"Discography-(\\d+)_\\d+.wav\", filename).group(1)) for filename in test_data.filenames]\n",
    "test_unique_song_ids = np.unique(test_song_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the audio samples that the human survey participants actually listened to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings of sample clips (14s)\n",
    "with open(\"universal_music/NHS_samples.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "dataset_config = DatasetConfig(**config['datasets'][0])\n",
    "embedding_filename = processor.get_embedding_path(dataset_config)\n",
    "dataset = processor.process_h5_file(embedding_filename, dataset_config)\n",
    "\n",
    "# Select the ones that align with the test set above\n",
    "sample_filenames = dataset.filenames\n",
    "sample_embeddings = dataset.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the songs selected to be in the test set from the sample audio dataset and prepare for model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_embeddings = []\n",
    "sample_song_ids = []\n",
    "sample_test_labels = []\n",
    "\n",
    "for i, filename in enumerate(sample_filenames):\n",
    "    id = int(re.search(r\"NAIV-(\\d+).wav\", filename).group(1))\n",
    "    if id in test_unique_song_ids:\n",
    "        sample_test_embeddings.append(sample_embeddings[i])\n",
    "        sample_song_ids.append(id)\n",
    "\n",
    "X_test_sample = np.array(sample_test_embeddings)\n",
    "X_test_scaled = scaler.transform(X_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the ground truth function of the full test audio, then aggregate so that there is one label per song. This part will not be necessary when comparing directly to human ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_id(filename):\n",
    "    return int(re.search(r\"Discography-(\\d+)_\\d+.wav\", filename).group(1))\n",
    "\n",
    "test_data_info = pd.DataFrame(data=zip(test_data.labels, test_data.filenames), columns=['labels','filenames'])\n",
    "test_data_info['id'] = test_data_info.filenames.apply(find_id)\n",
    "labels = test_data_info.groupby('id').first()\n",
    "\n",
    "y_true_sample = np.array([label_to_idx[label] for label in labels.labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sample = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the human ratings, add in the prediction according to each of the three policies, and filter to song ids present in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('universal_music/FFfull.csv', low_memory=False)\n",
    "web_df = df[df['study'] == 'web'].copy()\n",
    "\n",
    "# Add 'predictions' from each of the policies\n",
    "web_df['generous'] = np.load(\"universal_music/web_survey_ratings_generous.npy\")\n",
    "web_df['random']   = np.load(\"universal_music/web_survey_ratings_random.npy\")\n",
    "web_df['strict']   = np.load(\"universal_music/web_survey_ratings_strict.npy\")\n",
    "\n",
    "# Filter to only show songs in the test set\n",
    "web_df = web_df[web_df['song'].isin(sample_song_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_pred = dict(zip(sample_song_ids, y_pred_sample))\n",
    "web_df['model_pred'] = web_df['song'].map(id_to_pred)\n",
    "sample_predictions = web_df[['song', 'generous', 'random', 'strict', 'model_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
