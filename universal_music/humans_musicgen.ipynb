{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get aligned MusicGen predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/DAVIDSON/dutuller/Workspace/DRI1/MusicGen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DAVIDSON/dutuller/Workspace/DRI1/MusicGen/.venv/lib64/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/DAVIDSON/dutuller/Workspace/DRI1/MusicGen/\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import yaml\n",
    "from embeddings.h5_processor import H5DataProcessor, DatasetConfig, ProcessedDataset\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infrastructure for loading and splitting the embedding data from storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"universal_music/NHS_full.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Process datasets using H5DataProcessor\n",
    "processor = H5DataProcessor()\n",
    "all_train_data = []\n",
    "all_test_data = []\n",
    "class_names = set()\n",
    "\n",
    "# Process each dataset and split\n",
    "for dataset_config in config['datasets']:\n",
    "    dataset = processor.process_h5_file(\n",
    "        processor.get_embedding_path(DatasetConfig(**dataset_config)),\n",
    "        DatasetConfig(**dataset_config)\n",
    "    )\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_data, test_data = processor.get_train_test_split(\n",
    "        dataset, \n",
    "        test_ratio=0.2,\n",
    "        random_seed=42\n",
    "    )\n",
    "    \n",
    "    all_train_data.append(train_data)\n",
    "    all_test_data.append(test_data)\n",
    "    class_names.update(dataset.labels)\n",
    "\n",
    "# Combine datasets\n",
    "train_data = ProcessedDataset(\n",
    "    embeddings=np.vstack([d.embeddings for d in all_train_data]),\n",
    "    labels=[l for d in all_train_data for l in d.labels],\n",
    "    filenames=[f for d in all_train_data for f in d.filenames],\n",
    "    name=\"combined\",\n",
    "    num_samples=sum(d.num_samples for d in all_train_data)\n",
    ")\n",
    "\n",
    "test_data = ProcessedDataset(\n",
    "    embeddings=np.vstack([d.embeddings for d in all_test_data]),\n",
    "    labels=[l for d in all_test_data for l in d.labels],\n",
    "    filenames=[f for d in all_test_data for f in d.filenames],\n",
    "    name=\"combined\",\n",
    "    num_samples=sum(d.num_samples for d in all_test_data)\n",
    ")\n",
    "\n",
    "# Create and configure model\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier on the full songs from the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mapping for string class labels\n",
    "unique_labels = sorted(set(train_data.labels + test_data.labels))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert labels to indices\n",
    "X_train = train_data.embeddings\n",
    "y_train = np.array([label_to_idx[label] for label in train_data.labels])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify which song ids are present in the test set, so that we can find them among the sample audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_song_ids = [int(re.search(r\"Discography-(\\d+)_\\d+.wav\", filename).group(1)) for filename in test_data.filenames]\n",
    "test_unique_song_ids = np.unique(test_song_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the audio samples that the human survey participants actually listened to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings of sample clips (14s)\n",
    "with open(\"universal_music/NHS_samples.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "dataset_config = DatasetConfig(**config['datasets'][0])\n",
    "embedding_filename = processor.get_embedding_path(dataset_config)\n",
    "dataset = processor.process_h5_file(embedding_filename, dataset_config)\n",
    "\n",
    "# Select the ones that align with the test set above\n",
    "sample_filenames = dataset.filenames\n",
    "sample_embeddings = dataset.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the songs selected to be in the test set from the sample audio dataset and prepare for model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_embeddings = []\n",
    "sample_song_ids = []\n",
    "sample_test_labels = []\n",
    "\n",
    "for i, filename in enumerate(sample_filenames):\n",
    "    id = int(re.search(r\"NAIV-(\\d+).wav\", filename).group(1))\n",
    "    if id in test_unique_song_ids:\n",
    "        sample_test_embeddings.append(sample_embeddings[i])\n",
    "        sample_song_ids.append(id)\n",
    "\n",
    "X_test_sample = np.array(sample_test_embeddings)\n",
    "X_test_scaled = scaler.transform(X_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the ground truth function of the full test audio, then aggregate so that there is one label per song. This part will not be necessary when comparing directly to human ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_id(filename):\n",
    "    return int(re.search(r\"Discography-(\\d+)_\\d+.wav\", filename).group(1))\n",
    "\n",
    "test_data_info = pd.DataFrame(data=zip(test_data.labels, test_data.filenames), columns=['labels','filenames'])\n",
    "test_data_info['id'] = test_data_info.filenames.apply(find_id)\n",
    "labels = test_data_info.groupby('id').first()\n",
    "\n",
    "y_true_sample = np.array([label_to_idx[label] for label in labels.labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sample = model.predict(X_test_scaled)\n",
    "smaple_pred_lookup = dict(zip(sample_song_ids, y_pred_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the human ratings, filter to song ids present in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('universal_music/FFfull.csv', low_memory=False)\n",
    "web_df = df[df['study'] == 'web'].copy()\n",
    "\n",
    "# Add 'predictions' from each of the policies\n",
    "\n",
    "web_df = web_df[web_df['song'].isin(sample_song_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just apply the tiebreaking policies in here\n",
    "def policy_argmax_per_row(arr, true_labels, policy='random'):\n",
    "    \"\"\"\n",
    "    Vectorized implementation for finding argmax with specific tie-breaking policies:\n",
    "    - 'random': randomly select from ties\n",
    "    - 'generous': select the index that matches true_labels if possible (best case)\n",
    "    - 'strict': select the index that differs from true_labels if possible (worst case)\n",
    "    \n",
    "    Args:\n",
    "        arr: array of shape (n_samples, n_classes)\n",
    "        true_labels: array of true labels of shape (n_samples,)\n",
    "        policy: tie-breaking policy ('random', 'generous', or 'strict')\n",
    "    \"\"\"\n",
    "    # Get mask of all max values\n",
    "    max_vals = np.max(arr, axis=1, keepdims=True)\n",
    "    mask = (arr == max_vals)\n",
    "    \n",
    "    if policy == 'random':\n",
    "        # Original efficient random method\n",
    "        random_values = np.random.random(arr.shape) * mask\n",
    "        return np.argmax(random_values, axis=1)\n",
    "    \n",
    "    # Create a range array for comparing with true_labels\n",
    "    row_indices = np.arange(arr.shape[0])\n",
    "    \n",
    "    if policy == 'generous':\n",
    "        # For \"best case\" - prioritize the true label when it's among the max values\n",
    "        \n",
    "        # Check if true label is among the max values\n",
    "        true_label_is_max = mask[row_indices, true_labels]\n",
    "        \n",
    "        # Where true label is max, use it; otherwise use random tie-breaking\n",
    "        result = np.zeros(arr.shape[0], dtype=int)\n",
    "        \n",
    "        # For rows where true label is max, use the true label\n",
    "        result[true_label_is_max] = true_labels[true_label_is_max]\n",
    "        \n",
    "        # For rows where true label is not max, use random tie-breaking\n",
    "        non_match_rows = ~true_label_is_max\n",
    "        if np.any(non_match_rows):\n",
    "            # Create random values just for these rows\n",
    "            random_subset = np.random.random(arr[non_match_rows].shape) * mask[non_match_rows]\n",
    "            result[non_match_rows] = np.argmax(random_subset, axis=1)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    elif policy == 'strict':\n",
    "        # For \"worst case\" - avoid the true label when other max values exist\n",
    "        \n",
    "        # Create a penalty matrix - make true labels less favorable\n",
    "        penalty = np.zeros(arr.shape)\n",
    "        penalty[row_indices, true_labels] = 1\n",
    "        \n",
    "        # Apply penalty only to elements that are max\n",
    "        masked_penalty = penalty * mask\n",
    "        \n",
    "        # When choosing argmax with penalty, true labels will only be chosen\n",
    "        # if they're the only max value\n",
    "        random_values = np.random.random(arr.shape) * 0.1  # Small random values for secondary tie-breaking\n",
    "        selection_values = mask * (1 - masked_penalty + random_values)\n",
    "        \n",
    "        return np.argmax(selection_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two options: \n",
    "# 1. align the numpy 'ratings' files with song ids\n",
    "# 2. get the ground truth preds to run policy argmax in this notebook\n",
    "#     - still requires ground truth to be associated with the df in order to apply the policy argmax tho\n",
    "y_true_sample = np.array([label_to_idx[label] for label in labels.labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = web_df[[\"danc\",\"heal\",\"baby\",\"love\"]].copy().to_numpy()\n",
    "web_df['generous'] = policy_argmax_per_row(arr, y_true_sample, policy='generous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcasted_preds = many_df[id_column].map(id_to_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
